{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I Have skipped the push notification but craeated a separate path\n",
    "Code checks if Pushover credentials are available before attempting to send notifications. If not configured, it skips the external request and just prints locally. This allows the app to run without a Pushover account, while still supporting it if credentials are provided.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "import json\n",
    "import os\n",
    "import requests\n",
    "from pypdf import PdfReader\n",
    "import gradio as gr\n",
    "\n",
    "load_dotenv(override=True)\n",
    "# Initialize OpenAI client (requires OPENAI_API_KEY in .env).\n",
    "openai = OpenAI()\n",
    "\n",
    "# Pushover setup: Read user and token from environment variables.\n",
    "pushover_user = os.getenv(\"PUSHOVER_USER\")\n",
    "pushover_token = os.getenv(\"PUSHOVER_TOKEN\")\n",
    "pushover_url = \"https://api.pushover.net/1.messages.json\"\n",
    "\n",
    "# Print status of Pushover credentials for debugging.\n",
    "if pushover_user:\n",
    "    print(f\"Pushover user found and starts with {pushover_user[0]}\")\n",
    "else:\n",
    "    print(\"Pushover user not found\")\n",
    "\n",
    "if pushover_token:\n",
    "    print(f\"Pushover token found and starts with {pushover_token[0]}\")\n",
    "else:\n",
    "    print(\"Pushover token not found\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Safe push() function: Checks for credentials before sending.\n",
    "def push(message):\n",
    "    print(f\"Push: {message}\")\n",
    "    if pushover_user and pushover_token:\n",
    "        try:\n",
    "            payload = {\"user\": pushover_user, \"token\": pushover_token, \"message\": message}\n",
    "            resp = requests.post(pushover_url, data=payload, timeout=5)\n",
    "            if resp.ok:\n",
    "                print(\"Pushover: sent\")\n",
    "            else:\n",
    "                print(f\"Pushover: failed {resp.status_code} {resp.text}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Pushover error: {e}\")\n",
    "    else:\n",
    "        print(\"Pushover not configured; skipping external request.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to record user details: Calls push() to notify, then returns a confirmation dict.\n",
    "def record_user_details(email, name=\"Name not provided\", notes=\"not provided\"):\n",
    "    push(f\"Recording interest from {name} with email {email} and notes {notes}\")\n",
    "    return {\"recorded\": \"ok\"}\n",
    "\n",
    "# Function to record unknown questions: Calls push() to notify, then returns a confirmation dict.\n",
    "def record_unknown_question(question):\n",
    "    push(f\"Recording {question} asked that I couldn't answer\")\n",
    "    return {\"recorded\": \"ok\"}\n",
    "\n",
    "# JSON schema for record_user_details tool: Defines the tool's name, description, and parameters for the LLM.\n",
    "record_user_details_json = {\n",
    "    \"name\": \"record_user_details\",\n",
    "    \"description\": \"Use this tool to record that a user is interested in being in touch and provided an email address\",\n",
    "    \"parameters\": {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"email\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"The email address of this user\",\n",
    "            },\n",
    "            \"name\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"The user's name, if they provided it\",\n",
    "            },\n",
    "            \"notes\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"Any additional information about the conversation that's worth recording to give context\",\n",
    "            },\n",
    "        },\n",
    "        \"required\": [\"email\"],\n",
    "        \"additionalProperties\": False,\n",
    "    },\n",
    "}\n",
    "\n",
    "# JSON schema for record_unknown_question tool: Similar to above.\n",
    "record_unknown_question_json = {\n",
    "    \"name\": \"record_unknown_question\",\n",
    "    \"description\": \"Always use this tool to record any question that couldn't be answered as you didn't know the answer\",\n",
    "    \"parameters\": {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"question\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"The question that couldn't be answered\",\n",
    "            },\n",
    "        },\n",
    "        \"required\": [\"question\"],\n",
    "        \"additionalProperties\": False,\n",
    "    },\n",
    "}\n",
    "\n",
    "# List of tools: Passed to the OpenAI API so the LLM can call these functions.\n",
    "tools = [{\"type\": \"function\", \"function\": record_user_details_json},\n",
    "         {\"type\": \"function\", \"function\": record_unknown_question_json}]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Second, more elegant version of handle_tool_calls: Uses globals() to dynamically call functions.\n",
    "# Avoids the if statement, making it easier to add new tools.\n",
    "def handle_tool_calls(tool_calls):\n",
    "    results = []\n",
    "    for tool_call in tool_calls:\n",
    "        tool_name = tool_call.function.name\n",
    "        arguments = json.loads(tool_call.function.arguments)\n",
    "        print(f\"Tool called: {tool_name}\", flush=True)\n",
    "        tool = globals().get(tool_name)\n",
    "        result = tool(**arguments) if tool else {}\n",
    "        results.append({\"role\": \"tool\", \"content\": json.dumps(result), \"tool_call_id\": tool_call.id})\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load LinkedIn PDF and summary text: Extracts text from PDF and reads summary file.\n",
    "# Assumes files are in \"me/\" directory.\n",
    "reader = PdfReader(\"/Users/rohankajgaonkar/projects/agents/1_foundations/me/rohan_resume.pdf\")\n",
    "linkedin = \"\"\n",
    "for page in reader.pages:\n",
    "    text = page.extract_text()\n",
    "    if text:\n",
    "        linkedin += text\n",
    "\n",
    "with open(\"/Users/rohankajgaonkar/projects/agents/1_foundations/me/summary.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    summary = f.read()\n",
    "\n",
    "# Set the name (change this to your own name).\n",
    "name = \"Rohan\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# System prompt: Instructs the LLM to act as the person, using provided context.\n",
    "system_prompt = f\"You are acting as {name}. You are answering questions on {name}'s website, \" \\\n",
    "                f\"particularly questions related to {name}'s career, background, skills and experience. \" \\\n",
    "                f\"Your responsibility is to represent {name} for interactions on the website as faithfully as possible. \" \\\n",
    "                f\"You are given a summary of {name}'s background and LinkedIn profile which you can use to answer questions. \" \\\n",
    "                f\"Be professional and engaging, as if talking to a potential client or future employer who came across the website. \" \\\n",
    "                f\"If you don't know the answer to any question, use your record_unknown_question tool to record the question that you couldn't answer, even if it's about something trivial or unrelated to career. \" \\\n",
    "                f\"If the user is engaging in discussion, try to steer them towards getting in touch via email; ask for their email and record it using your record_user_details tool. \"\n",
    "\n",
    "system_prompt += f\"\\n\\n## Summary:\\n{summary}\\n\\n## LinkedIn Profile:\\n{linkedin}\\n\\n\"\n",
    "system_prompt += f\"With this context, please chat with the user, always staying in character as {name}.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chat function: Handles the conversation loop with the LLM.\n",
    "# Builds messages, calls OpenAI with tools, handles tool calls if needed, and returns the response.\n",
    "def chat(message, history):\n",
    "    messages = [{\"role\": \"system\", \"content\": system_prompt}] + history + [{\"role\": \"user\", \"content\": message}]\n",
    "    done = False\n",
    "    while not done:\n",
    "        # Call the LLM with tools enabled.\n",
    "        response = openai.chat.completions.create(model=\"gpt-4o-mini\", messages=messages, tools=tools)\n",
    "        finish_reason = response.choices[0].finish_reason\n",
    "        \n",
    "        # If the LLM wants to call tools, execute them and continue.\n",
    "        if finish_reason == \"tool_calls\":\n",
    "            message = response.choices[0].message\n",
    "            tool_calls = message.tool_calls\n",
    "            results = handle_tool_calls(tool_calls)\n",
    "            messages.append(message)\n",
    "            messages.extend(results)\n",
    "        else:\n",
    "            done = True\n",
    "    return response.choices[0].message.content\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Launch Gradio interface: Creates a chat UI for the app.\n",
    "gr.ChatInterface(chat).launch(pwa = True, share = True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
